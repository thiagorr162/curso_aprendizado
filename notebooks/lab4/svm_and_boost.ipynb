{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc3162b4-5044-49d9-b4f6-b732910f988e",
   "metadata": {},
   "source": [
    "# Exercício: Classificação com SVM RBF em Dados Estilo Checkerboard\n",
    "\n",
    "Você irá:\n",
    "\n",
    "1. Gerar um conjunto de dados com padrão de tabuleiro (checkerboard).\n",
    "2. Treinar um modelo SVM com kernel RBF.\n",
    "3. Visualizar os pontos e os vetores de suporte.\n",
    "4. Explorar diferentes valores de `C`, `gamma` e da quantidade de tiles.\n",
    "\n",
    "---\n",
    "\n",
    "## Passo 1: Gerar os dados\n",
    "\n",
    "Use a função abaixo para gerar pontos em `[0,1]^2` com classes alternadas em padrão de tabuleiro:\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    def generate_checkerboard(n_samples=1000, n_tiles=3, seed=42):\n",
    "        np.random.seed(seed)\n",
    "        X = np.random.uniform(0, 1, size=(n_samples, 2))\n",
    "        y = ((np.floor(X[:, 0] * n_tiles) + np.floor(X[:, 1] * n_tiles)) % 2).astype(int)\n",
    "        return X, y\n",
    "\n",
    "Exemplo:\n",
    "\n",
    "    X, y = generate_checkerboard()\n",
    "\n",
    "Experimente mudar o valor de `n_tiles` (por exemplo: `n_tiles = 2, 4, 6`) e observe como o padrão se torna mais complexo.\n",
    "\n",
    "---\n",
    "\n",
    "## Passo 2: Treinar o modelo\n",
    "\n",
    "Treine um classificador SVM com kernel `'rbf'`:\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    C = 10\n",
    "    gamma = 1\n",
    "    model = SVC(kernel='rbf', C=C, gamma=gamma)\n",
    "    model.fit(X, y)\n",
    "\n",
    "---\n",
    "\n",
    "## Passo 3: Visualizar os resultados\n",
    "\n",
    "Plote os dados com `matplotlib.pyplot.scatter`, colorindo os pontos pela classe e destacando os vetores de suporte em preto.\n",
    "\n",
    "---\n",
    "\n",
    "## Passo 4: Extrair os vetores de suporte\n",
    "\n",
    "Use a função abaixo para obter os vetores de suporte do modelo treinado:\n",
    "\n",
    "    model.support_vectors_\n",
    "\n",
    "---\n",
    "\n",
    "## Passo 5: Explorar os hiperparâmetros\n",
    "\n",
    "Repita os passos anteriores para diferentes combinações de:\n",
    "\n",
    "- `C = 1, 10, 100`\n",
    "- `gamma = 0.1, 1, 10`\n",
    "- `n_tiles = 2, 3, 4`\n",
    "\n",
    "Documente suas conclusões."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81db7ae-964b-4dc1-8323-31c1509cc1ed",
   "metadata": {},
   "source": [
    "# Exercício: Curva de Aprendizado com AdaBoost\n",
    "\n",
    "Você irá:\n",
    "\n",
    "- Carregar o arquivo `boost.csv`.\n",
    "- Separar os dados em treino e calibração.\n",
    "- Treinar um modelo `AdaBoostClassifier`.\n",
    "- Usar `staged_predict` para calcular o erro de classificação em cada etapa.\n",
    "- Plotar as curvas de erro no treino e calibração ao longo das iterações.\n",
    "\n",
    "---\n",
    "\n",
    "## Importações\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.metrics import zero_one_loss\n",
    "\n",
    "---\n",
    "\n",
    "## Observação sobre `staged_predict`\n",
    "\n",
    "O método `staged_predict` do AdaBoost permite acessar as **previsões parciais** do modelo a cada iteração (número crescente de estimadores).\n",
    "\n",
    "Você pode usá-lo assim:\n",
    "\n",
    "    for y_pred in model.staged_predict(X):\n",
    "        erro = zero_one_loss(y_true, y_pred)\n",
    "\n",
    "Para comparar treino e calibração simultaneamente:\n",
    "\n",
    "    for y_pred_train, y_pred_calib in zip(\n",
    "        model.staged_predict(X_train),\n",
    "        model.staged_predict(X_calib)\n",
    "    ):\n",
    "        # calcule e armazene os erros para treino e calibração\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90363cb7-ca2a-4792-b414-e810ac4bcb94",
   "metadata": {},
   "source": [
    "# Exercício: Intervalo de Predição com Gradient Boosting\n",
    "\n",
    "Neste exercício, você irá:\n",
    "\n",
    "- Gerar um dataset com variância heterocedástica.\n",
    "- Visualizar a função geradora.\n",
    "- Utilizar regressão quantílica com Gradient Boosting para estimar intervalos de predição de 90%.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Gerar o dataset\n",
    "\n",
    "Utilize a função abaixo para gerar os dados. Ela simula uma relação não linear com variância que depende da posição:\n",
    "\n",
    "    def make_variable_data(n, std_dev=1/5):\n",
    "        x = np.random.uniform(low=-1, high=1, size=n)\n",
    "        y = (x**3) + 2 * np.exp(-6 * (x - 0.3)**2)\n",
    "        y = y + np.random.normal(scale=std_dev * np.abs(x), size=n)\n",
    "        df = pd.DataFrame({'x': x, 'y': y})\n",
    "        return df\n",
    "\n",
    "Gere os dados com `n = 2000` e plote os pontos junto com a curva determinística (isto é, sem o ruído) para visualizar a variabilidade dos dados.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Separar os dados\n",
    "\n",
    "Use `train_test_split` para dividir os dados em treino e teste.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Treinar modelos quantílicos\n",
    "\n",
    "Treine três modelos `GradientBoostingRegressor` com `loss='quantile'` usando:\n",
    "\n",
    "- `alpha = 0.05` para o limite inferior\n",
    "- `alpha = 0.5` para a mediana\n",
    "- `alpha = 0.95` para o limite superior\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Visualizar os resultados\n",
    "\n",
    "Plote os dados de treino como pontos, a curva da mediana como linha, e o intervalo de predição como duas curvas (superior e inferior) com cores diferentes.\n",
    "\n",
    "---\n",
    "\n",
    "Esse exercício mostra como estimar intervalos de predição com Gradient Boosting e como eles se adaptam à variância dos dados.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
